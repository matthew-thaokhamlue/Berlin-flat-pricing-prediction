{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d7df82",
   "metadata": {},
   "source": [
    "# Fun project creating regressor for Berlin flat price using data from 2019\n",
    "\n",
    "## steps to approach the project\n",
    "\n",
    "1. Preprosess data i.e. PCA finding the make-sense features, \n",
    "2. EDA the cleansed dataset\n",
    "3. Modeling\n",
    "4. Model evaluation\n",
    "5. Deploy model using FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce98b9",
   "metadata": {},
   "source": [
    "## step 1: Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366ed46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = pd.read_csv('berlin-houses.csv')\n",
    "df_org.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af9f69",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used for the analysis can be found in the file `berlin-houses.csv`\n",
    "\n",
    "The variables of this dataset are:\n",
    "\n",
    "- `id` - id of listing\n",
    "- `lat` - latitude of the listing\n",
    "- `lon` - longitude of the listing\n",
    "- `cold_price` - price of the listing before heating and upkeep costs\n",
    "- `warm_price` - price of the listing after heating and upkeep costs\n",
    "- `currency` - currency of the listing prices\n",
    "- `short_listed` - if a given listing has short listed candidates\n",
    "- `postcode_id` - post code of the listing\n",
    "- `balcony` - if a listing has a balcony\n",
    "- `builtin_kitchen` - if a listing has a built-in kitchen\n",
    "- `created_date` - date the listing was created\n",
    "- `modified_date` - date the listing was modified\n",
    "- `published_date` - date the listing was published\n",
    "- `energy_certificate` - if a listing has an energy certificate\n",
    "- `has_new_flag` - if a listing is a new build or has been renovated recently.\n",
    "- `living_space` - the living area in squared meters (m2)\n",
    "- `new_home_builder` - if a listing has been built by new building company\n",
    "- `number_rooms` - total number of rooms in listing\n",
    "- `private_offer` - if a listing is pusblished by private owner\n",
    "- `address` - address of the listing\n",
    "- `link` - link to listing page\n",
    "- `quarter` - district where listing is located\n",
    "- `garden` - if a listing has a garden\n",
    "- `listing_type` - listing size category\n",
    "- `localhost_date` - date when listing data was saved into database\n",
    "- `no_longer_available` - if listing is no longer available in website\n",
    "- `no_longer_available_date` - date when listing was no longer available on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555df2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = df_org.columns.values\n",
    "useful_feats = df_org.drop(columns=['id','currency','cold_price','currency','short_listed',\n",
    "                                'created_date','published_date',\n",
    "                                'modified_date','address','link',\n",
    "                                'listing_type','localhost_date','no_longer_available',\n",
    "                                'no_longer_available_date','quarter']).columns.values\n",
    "num_feats = ['lat', 'lon','number_rooms','living_space','warm_price']\n",
    "cat_feats = df_org[useful_feats].drop(num_feats,axis=1).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a852787",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['id','currency','cold_price','currency','short_listed',\n",
    "                                'created_date','published_date',\n",
    "                                'modified_date','address','link',\n",
    "                                'listing_type','localhost_date','no_longer_available',\n",
    "                                'no_longer_available_date','quarter']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d55fa151",
   "metadata": {},
   "source": [
    "### Reason for dropping below columns\n",
    "- `cold_price` col is dropped as it is redundent to `warm_price`\n",
    "- `quarter` col is dropped as `lat`, `long`, and `PLZ` are chosen as location information group\n",
    "- `address` col is dropped as it is redundent to location information group\n",
    "\n",
    "**Below features are dropped as they are rather metadata of the flat and don't add any value to the model trainning**\n",
    "- `id` \n",
    "- `currency` \n",
    "- `currency` \n",
    "- `short_listed` \n",
    "- `created_date` \n",
    "- `published_date` \n",
    "- `modified_date` \n",
    "- `link` \n",
    "- `listing_type` \n",
    "- `localhost_date` \n",
    "- `no_longer_available` \n",
    "- `no_longer_available_date` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cdd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org[useful_feats].dropna()\n",
    "df['postcode_id'] = df['postcode_id'].astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532989ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_feats].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb84d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_feats].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df[useful_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d9cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_analysis.drop(columns=['warm_price'])\n",
    "y = df_analysis['warm_price']\n",
    "SEED = 42\n",
    "\n",
    "# Create a PCA model with 10 components\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "# Fit the model to the data and transform the data\n",
    "X_transformed = pca.fit_transform(X)\n",
    "\n",
    "# Get the explained variance ratio of each component\n",
    "explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bar chart\n",
    "plt.bar(range(len(explained_variance)), explained_variance)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365901c",
   "metadata": {},
   "source": [
    "Clearly PCA doesn't help. I will then use RandomForest to determine feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9402d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=16, \n",
    "                           n_estimators=700, \n",
    "                           max_features='log2', \n",
    "                           random_state=SEED) \n",
    "\n",
    "rfr.fit(X,y)\n",
    "\n",
    "importance = rfr.feature_importances_\n",
    "\n",
    "f_importance = {}\n",
    "for i in range(len(df_analysis.drop(columns=['warm_price']).columns)):\n",
    "     f_importance[df_analysis.drop(columns=['warm_price']).columns[i]] = importance[i]\n",
    "        \n",
    "plt.bar(f_importance.keys(),f_importance.values())\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Feature Importance in RF Regression Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a2262",
   "metadata": {},
   "source": [
    "From RandomForestRegressor feature importance, living space takes highest importance, and followed by location information group, and then if the flat has EBK or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c82ef",
   "metadata": {},
   "source": [
    "## step 2: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103edcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df[num_feats].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8f427",
   "metadata": {},
   "source": [
    "From numerical features perspective, belows are spotted:\n",
    "- number of rooms correlates with living space positively\n",
    "- The flat price has mild correlations with all numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_analysis,x='postcode_id').set(title='The Distribution of flat per PLZ')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_feats].columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d19794",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,7,figsize=(20,3))\n",
    "# sns.countplot(data=df_analysis,x='balcony', ax=axes[0])\n",
    "# sns.countplot(data=df_analysis,x='builtin_kitchen', ax=axes[1])\n",
    "# sns.countplot(data=df_analysis,x='energy_certificate', ax=axes[2])\n",
    "\n",
    "for i, col in enumerate(df[cat_feats].columns[1:]):\n",
    "    sns.countplot(data=df_analysis,x=col,ax=axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d23abc",
   "metadata": {},
   "source": [
    "We can even drop `new_home_builder` feature since all values are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = df_analysis.drop(columns=['new_home_builder','warm_price']).columns.values\n",
    "final_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b922e",
   "metadata": {},
   "source": [
    "## step 3: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f586cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[final_features]\n",
    "y = df['warm_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ac9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(X_train,y_train)\n",
    "y_pred = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2de846",
   "metadata": {},
   "source": [
    "## step 4: Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test,y_pred)\n",
    "RMSE = mean_squared_error(y_test,y_pred,squared=False)\n",
    "print(f\"Model r2: {r2}\")\n",
    "print(f\"Model RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5e4a1",
   "metadata": {},
   "source": [
    "## step 4.1: Retry with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['lat', 'lon', 'postcode_id','builtin_kitchen','living_space']]\n",
    "y = df['warm_price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "rfr.fit(X_train,y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "RMSE = mean_squared_error(y_test,y_pred,squared=False)\n",
    "print(f\"Model r2: {r2}\")\n",
    "print(f\"Model RMSE: {RMSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2b72c",
   "metadata": {},
   "source": [
    "## step 4.2: Retry with other model - DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c99532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "402f24a1",
   "metadata": {},
   "source": [
    "## step 5: Serve the model using FastAPI - still on the to do list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c03b49b",
   "metadata": {},
   "source": [
    "## step 6: Deploy model to streamlit or Heroku - still on the to do list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff2f5c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
